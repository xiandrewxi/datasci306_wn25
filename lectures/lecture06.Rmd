---
title: "Stats 306: Lecture 6"
subtitle: "Tables: Filtering, Selecting, Grouping and Summaries"
output: 
  learnr::tutorial:
    progressive: true
    css: css/lecture.css
runtime: shiny_prerendered
---


```{r setup, include=FALSE}
library(learnr)
library(tidyverse)
library(lubridate) # install.packages("lubridate") if you don't have this
aatemp <- read_csv("data/ann_arbor_weather.csv.gz")
```

## Tables: lists of vectors

Review:

* Samples: collections of $n$ units
* Variables: $k$ measurements common to all units
* Tables ($n \times k$): units on rows, variables on columns
* Conceptual table implementation: lists of length $k$ composed of vectors of length $n$

Example:
```{r}
x <- 1:10
y <- 100:109
length(x)
length(y)
d <- list(column_x = x, column_y = y)
d
d$column_x
```

## Better tables: `data.frame` and `tibble`

A list of vectors could not guarantee they are all the same length. Instead we use **`data.frame`** and **`tibble`**.

```{r}
d2 <- as.data.frame(d)
dim(d2)
d3 <- as_tibble(d2)
d3
```

## Common operations on tables (overview)

* Pulling out a single column: `d$col`
* Creating a single column: `d$newcol <- EXPR`
* Pulling out several columns: `select(d, col1, col2)` (and several other forms)
* Pulling out rows: `filter(d, criterion1, criterion2)`
* Creating new columns (in new table): `mutate(d, newcol = f(col1, col2), newcol2 = g(col3, newcol))`
* Grouping and summarizing `group_by(d, discrete_column) |> summarize(new_name = f(col))`

## Getting and setting columns (one at a time)

Recall: to get something out of a list, use the dollar sign `$` operator

```{r}
d3$column_x
d3$x_plus_y <- d3$column_x + d3$column_y
head(d3, 2)
```

## Getting several columns at once

```{r}
select(d3, column_x, x_plus_y) |> head(2)
```

## Getting all but some columns

```{r}
select(d3, !column_x) |> head(2)
```

## Selectively grabbing columns

```{r}
d3$letter <- letters[d3$column_x]
d3$LETTER <- LETTERS[27 - d3$column_x]
head(d3, 2)
```
Get only "character" type columns:
```{r}
select(d3, where(is.character)) |> head(2)
```

## 'is' functions for columns

* `is.character`: strings/character vectors
* `is.numeric`: number/numeric
* `is.factor`: factor/categories
* `is.logical`: logical/boolean
* `is.double`, `is.integer`: decimal and integer numeric types, respectively

When we start to write our own functions, we'll be able to create many more

## Grabbing rows by index

Tables in R allow for **two-dimensional indexing**: `tbl[rows, cols]`.

```{r}
d3[1, ]
d3[2:4, ]
d3[, c("column_x", "LETTER")]
d3[1:3, c("letter", "LETTER")]
```

## Grabbing rows by criteria (old school)

```{r}
d3[d3$column_y > 105, ]
```

## Grabbing rows (new school)

```{r}
filter(d3, column_y > 105)
```

## Multiple criteria

```{r}
filter(d3, column_y > 105 & column_x < 9)
```

```{r}
filter(d3, column_y > 108 | column_x  < 3)
```

## Exercise

Combine `filter` and `select` to get only the columns `cty` and `hwy` for cars that have more than 4 cylinders.

```{r}
head(mpg, 1)
```

```{r filter-select, exercise = TRUE}

```

## Tasks
* Creating new column (in new table): `mutate(d, newcol = f(col1, col2))`
* Grouping and summarizing `group_by(d, discrete_column) |> summarize(new_name = a_function(col))`

## Mutate: create columns

Before we had code like:
```{r eval = FALSE}
df$new_column <- f(df$x, df$y)
```

It would be convenient to avoid the repeated `df$`:
```{r eval = FALSE}
new_df <- mutate(df, new_column = f(x, y))
```

## Mutate creates new tables

```{r}
aatemp <- read_csv("data/ann_arbor_weather.csv.gz")
dim(aatemp)
aatemp2 <- mutate(aatemp, tdiff = c(NA, diff(TMAX)))
dim(aatemp)
dim(aatemp2)
```

## Mutate for multiple columns

```{r}
aatemp3 <- mutate(aatemp,
                  tdiff = c(NA, diff(TMAX)),
                  tdiff_abs = abs(tdiff))
```

## Mutate to remove columns

```{r}
# NB: reassigning to same variable name
aatemp3 <- mutate(aatemp3, tdiff = NULL)
colnames(aatemp3)
```

## Using helper functions

Recall a $Z$-score is defined by:
$$Z = \frac{X - \bar X}{\hat \sigma}$$

```{r}
aatemp3 <- filter(aatemp3, !is.na(tdiff_abs))
aatemp3 <- mutate(aatemp3, z = (tdiff_abs - mean(tdiff_abs)) / sd(tdiff_abs))
ggplot(aatemp3, aes(x = z)) + geom_histogram()
```

## Conditional evaluation with `if_else`

We may want to create new values using a condition. The `if_else` and function can help:
```{r}
if_else(c(TRUE, FALSE, FALSE), c("aT", "bT", "cT"), c("aF", "bF", "cF"))
```

R will also "recycle" values, so we can pass in single value that will get repeated:
```{r}
x <- c(-2, 1.4, -0.25, 7)
if_else(x < 0, 0, x)
```

There is also `ifelse`, which is similar, but a bit more permissive in what it allows for the two result vectors.

## Exercise

We often want to express variables on a different scale, such as constraining them to be between 0 and 1:
$$Y_i = \frac{X_i - \min(X)}{ \max(X) - \min(X)}$$

Use `mutate` to rescale `x` in this data: 
```{r rescale, exercise= TRUE}
d <- data.frame(x = rnorm(10))

```

## Exercise

Use `if_else` to replace any value greater than 1 with the value 1 and any value less than -1 with the value -1 (this is called "top coding").(*Hint*: you may want to do it two steps.)

```{r topcoding, exercise = TRUE}
d <- data.frame(x = c(-0.19, 1.35, 1.21, -0.11, -0.99, 
                      -0.4, -0.04, -0.4, 0.82, -1.55))

```

```{r topcoding-solution}
d <- data.frame(x = c(-0.19, 1.35, 1.21, -0.11, -0.99, 
                      -0.4, -0.04, -0.4, 0.82, -1.55))

mutate(d,
  tmp = if_else(x < -1, -1, x),
  top = if_else(x > 1, 1, tmp),
  tmp = NULL # remove from table
)
```


## `transmute`: `mutate` + `select`

If you only want the new column(s), you can use `transmute`:

```{r}
transmute(aatemp, degrees_from_freezing = abs(TMAX - 32)) |> summary()
```



## Temperature data for Ann Arbor, MI

```{r}
# to run this line from the console, use `setwd("lectures")` first
aatemp
```

## `mutate` to add a column

```{r}
aatemp_cel <- mutate(aatemp, TMAX_celsius = (TMAX - 32) * 5/9) |>
  select(TMAX, TMAX_celsius)
```

## `summary` and `summarize`

R has a built in a function called `summary` that gives a distilled look at a table:
```{r}
aat_4col <- select(aatemp, c("STATION", "DATE", "TMAX", "SNOW"))
summary(aat_4col)
```

The `summarize` function is from `dplyr` (part of `tidyverse`) and allows computing arbitrary summaries.

```{r}
summarize(aat_4col, avg_TMAX = mean(TMAX), days_of_snow = sum(!is.na(SNOW)))
```

## Summarize variations: `_if`, `_at`, `_all`

```{r}
select(aatemp, where(is.numeric)) |> summarize_all(mean, na.rm = TRUE)
summarize_if(aatemp, is.numeric, var, na.rm = TRUE)
summarize_at(aatemp, c("TMAX", "TMIN"), c(maximum = max, minimum = min))
```

## Exercise

For the `mpg` data set, compute the mean `hwy` mileage and median `cty` mileage. Compute the variance of the ratio of `hwy` to `city`.
```{r summary, exercise = TRUE}

```

## Grouping

Often we want to break data out across categories and compute summaries within each.

```{r}
group_by(aatemp, year(DATE)) |> summarize(avg_TMAX = mean(TMAX), days_of_snow = sum(!is.na(SNOW)))
```

## Inspecting group data

```{r}

aat_year <- group_by(aatemp, year(DATE))
nrow(aat_year) == nrow(aatemp)
colnames(aat_year)[18]
group_vars(aat_year)
```

## Grouping by year and month
```{r}
aat_year_month <- group_by(aat_year, month(DATE), .add = TRUE)
group_vars(aat_year_month)
```

```{r}
aat_year_month <- group_by(aatemp, year(DATE), month(DATE))
group_vars(aat_year_month)
```

## Aggregating up with `summarize` function

```{r}
summarize(aat_year_month, avg_TMAX = mean(TMAX)) |>
  ggplot(aes(x = `year(DATE)` + `month(DATE)` / 12, avg_TMAX)) +
  geom_line()

```

## Aggregating up two levels

```{r}
summarize(aat_year_month, monthly_avg_tmax = mean(TMAX)) |>
  summarize(yearly_median_monthy_mean = median(monthly_avg_tmax))
```

## Exercise

Using the `mpg` data set, find the manufacturer (`manufacturer`) with the highest mean highway efficiency (`hwy`)
```{r manufacturer-hwy, exercise = TRUE}

```

## Arranging output

Sometimes we want to choose the ordering of rows in a table. I don't use this a lot for raw data, but it can be quite helpful for summaries:

```{r}
group_by(aatemp, year(DATE)) |> 
  summarize(yearly_maxT = max(TMAX)) |> 
  arrange(yearly_maxT)
```

## Descending order, multiple columns


```{r}
group_by(aatemp, year(DATE)) |> 
  summarize(yearly_maxT = max(TMAX), yearly_minT = min(TMAX)) |> 
  arrange(desc(yearly_maxT), yearly_minT)
```

## Exercise

Group by both `manufacturer` and `class`. What manufacturer has the highest `cty` efficiency in the sense of the median of mean `cty` within class?

```{r manufacturer-hwy, exercise = TRUE}
```


## Grouping by year
```{r}
aat_year <- group_by(aatemp, year(DATE))
summarize(aat_year, median(TMAX - TMIN, na.rm = TRUE))
```
## Useful functions for summaries

* Seen before: `mean`, `median`, `sd`, `min`, `max`
* Other common statistical measures: `quantile`, `IQR`
* For boolean/logical columns: `any` and `all` ("or" and "and" across vectors)
* The functions `n` and a `n_distinct` count units and distinct values

## Some more summaries

```{r}
summarize(aat_year, n(), n_distinct(TMAX), any(SNOW > 10))
```

## Centered temperature

```{r}
mutate(aatemp, TMAX_centered = TMAX - mean(TMAX)) |>
 ggplot(aes(y = TMAX_centered, x = factor(quarter(DATE)))) +
    geom_violin() 
```

## `mutate` and `group_by`

Observe some care when using `mutate` on grouped tables:

```{r}
group_by(aatemp, quarter(DATE)) |>
  mutate(TMAX_centered = TMAX - mean(TMAX)) |>
  ggplot(aes(y = TMAX_centered, x = factor(`quarter(DATE)`))) +
    geom_violin()
```

## Normalizing by monthly averages?

Let's center each observation by it's monthly average that we can understand if
it was unusual for that time of year.

```{r}
aat_month_centered <- group_by(aatemp, month(DATE)) |>
  mutate(TMAX_centered = TMAX - mean(TMAX, na.rm = TRUE)) # mean computed over months
## verify as the variance should be pr
summarize(aat_month_centered, var(TMAX_centered), sum(TMAX_centered^2) / (n() - 1)) |>
  head(3)
```

## Unusual months continued: conversion to ranks

*Ranks* are a useful robust replacement for values that are less susceptible to outliers. Let's rank days by how far they were from their monthly mean.

**Danger**: mutate will operate within months!

```{r}
mutate(aat_month_centered, r = rank(TMAX_centered)) |> 
  summarize(min(r), max(r))
```

## Ungrouping to fix

We need to drop the grouping values so that we can rank across all days.

```{r}
ungroup(aat_month_centered) |> 
  mutate(aat_month_centered, r = rank(TMAX_centered)) |>
  summarize(min(r), max(r))
```

## Average rank within years

Now that we can rank across all years and months, what year had the highest
average ranks?

```{r}
ungroup(aat_month_centered) |> 
  mutate(aat_month_centered, r = rank(TMAX_centered)) |>
  group_by(year(DATE)) |>
  summarize(mean(r)) |>
  arrange(desc(`mean(r)`))
```

## Exercise

Let's put it all together using the `mpg` data set.

>* Get a list of manufacturers that produce cars in at least 2 different classes. (Recall `n_distinct` function)
>* Using that list, subset the `mpg` data to just those manufactures
>* Rescale the highway efficiency variable into Z-scores (using the common mean across all manufacturers)
>* Group the observations by manufacturer. Which one has the smallest variance in `cty` efficiency?

You may want to use `%in%`:
```{r}
c("Hi", "Low", "Low", "Medium") %in% c("Medium", "High")
```

```{r lastex, exercise = TRUE}

```

```{r lastex-solution}
at_least_2 <- group_by(mpg, manufacturer) |> 
  summarize(per_class = n_distinct(class)) |>
  filter(per_class > 1)

at_least_2

filter(mpg, manufacturer %in% at_least_2$manufacturer) |>
  mutate(cty_z = scale(cty)) |>
  group_by(manufacturer) |>
  summarize(v = var(cty_z)) |>
  arrange(v)
```

## Other R functions

Most other R functions do not recognize grouping:

```{r}
mean(aatemp$TMAX, na.rm = TRUE)
mean(aat_year$TMAX)
summarize(aat_year, mean(TMAX))
```


